{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0db36b3",
   "metadata": {},
   "source": [
    "# Exploration 7. 머신러닝 모델을 제품으로 만들어보자 : MLOps 기초\n",
    "**MLOps 이론 공부**\n",
    "\n",
    "## 학습 목표 및 내용\n",
    "- 지금까지 만들었던 딥러닝 모델을 KerasTuner로 하이퍼파라미터 튜닝을 한 뒤에 TFServing으로 API, tflite 파일 생성\n",
    "- 머신러닝 모델을 실험실에서만 진행했을때 생기는 문제점\n",
    "- MLOps의 정의, ML 시스템의 구성요소\n",
    "- TFX (TensorFlow Extended) \n",
    "     - **Keras Tuner, TensorFlow Serving**\n",
    "- KerasTuner를 활용해서 **하이퍼 파라미터 튜닝**\n",
    "- TensorFLow Serving과 TFLite로 **모델 배포**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1673c0c6",
   "metadata": {},
   "source": [
    "# TFX - Keras Tuner\n",
    "- 하이퍼파라미터 튜닝\n",
    "- keras의 MNIST 데이터셋 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ccee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # install KerasTuner \n",
    "# !mkdir ~/aiffel/mlops\n",
    "# !pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b653d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa89d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73791e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add extra dimension for CNN \n",
    "X_train = x_train.reshape(-1,28, 28, 1) \n",
    "X_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "# label encoding - categorical \n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data - train, validation = 8:2 \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49051fa0",
   "metadata": {},
   "source": [
    "## DeepTuner\n",
    "- `kerastuner.Tuner`를 인자로 하는 class\n",
    "- `run_trial`,`save_model`,`load_model` 함수 실행\n",
    "    - `run_trial`에서 중요한 부분! : `hypermodel`, `trial`\n",
    "  \n",
    "  \n",
    "**KerasTuner의 hypermodel**\n",
    "\n",
    "- 모델 공유 및 재사용하기 위해 검색 공간을 캡슐화하는 모델\n",
    "- `hp` 인수를 사용해서 `keras.Model` 생성\n",
    "    - 만들고 싶은 모델을 쌓는 과정에서 하이퍼파라미터 튜닝을 위한 검색공간을 만들때 hp 인수를 사용해서 모델 생성\n",
    "- `build` 메소드를 활용하면 **모델빌드 + 하이퍼파라미텨 튜닝 시작**\n",
    "\n",
    "\n",
    "**KerasTuner의 trial**\n",
    "- Oracle에 속하는 class\n",
    "    - Oracle : KerasTuner`의 모든 검색 알고리즘에서 사용하는 기본 클래스\n",
    "- 종류 : RandomSearchOracle, BayesianOptimizationOracle, HyperbandOracle\n",
    "    - KerasTuner가 하이퍼파라미터를 정할때 사용하는 알고리즘\n",
    "- `trial.hyperparameter` : Oracle이 찾아야하는 하이퍼파라미터\n",
    "    - = `hypermodel`의 `hp`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aebe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepTuner(kt.Tuner):\n",
    "    def run_trial(self, trial, X, y, validation_data, **fit_kwargs):\n",
    "        model = self.hypermodel.build(trial.hyperparameters)      # 모델빌드 + 하이퍼파라미터 튜닝 시작\n",
    "        model.fit(X, y, batch_size=trial.hyperparameters.Choice(  # trial : batch size 검색\n",
    "            'batch_size', [16, 32]), **fit_kwargs)\n",
    "\n",
    "\n",
    "        X_val, y_val = validation_data\n",
    "        eval_scores = model.evaluate(X_val, y_val)\n",
    "        return {name: value for name, value in zip(\n",
    "            model.metrics_names,\n",
    "            eval_scores)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa680b27",
   "metadata": {},
   "source": [
    "## Build model\n",
    "- hypermodel 생성\n",
    "- `hp` 변수로 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.Input(shape = X_train.shape[1:], name = 'inputs'))  # hypermodel은 input 지정 필수\n",
    "    \n",
    "    # Con2D layer 개수 검색 (1~10개)\n",
    "    for i in range(hp.Int('num_layers', min_value=1, max_value=10)):       \n",
    "              model.add(tf.keras.layers.Conv2D(hp.Int(         # conv2d units 검색 (32~128 범위)           \n",
    "                  'units_{i}'.format(i=i), min_value=32, max_value=128, step=5), (3,3),activation='relu'))\n",
    "            \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    \n",
    "    # Dense layer 개수 검색 (1~3개)\n",
    "    for i in range(hp.Int('n_connections', 1, 3)):\n",
    "        model.add(tf.keras.layers.Dense(hp.Choice(f'n_nodes',        # dense units 검색 (32, 64, 128, 256 중 선택)\n",
    "                                  values=[32,64,128, 256]), activation = 'relu'))   \n",
    "        \n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax', name = 'outputs'))\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce184909",
   "metadata": {},
   "source": [
    "## KerasTuner 정의 & 파라미터 탐색\n",
    "- BayesianOptimizationOracle을 사용\n",
    "    - Objective :accuracy, max\n",
    "    - trial : 10\n",
    "- `search` : 파라미터 탐색 함수\n",
    "- 무거운 모델을 돌릴경우 하이퍼파라미터 튜닝 작업 소요시간이 늘어남\n",
    "    - **search epoch를 3-4로 작게 설정 -> 최고의 하이퍼파라미터 추출 -> 본격 모델학습때 epoch를 넉넉하게 설정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make keras tuner\n",
    "my_keras_tuner = DeepTuner(\n",
    "    oracle=kt.oracles.BayesianOptimizationOracle(\n",
    "        objective=kt.Objective('accuracy', 'max'),\n",
    "        max_trials=10,\n",
    "        seed=42),\n",
    "    hypermodel=build_model,\n",
    "    overwrite=True,\n",
    "    project_name='my_keras_tuner')\n",
    "\n",
    "# Navigate parameters\n",
    "my_keras_tuner.search(\n",
    "    X_train, y_train, validation_data=(X_val, y_val), epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a7632d",
   "metadata": {},
   "source": [
    "## Select best hyperparameter\n",
    "- `KerasTuner.get_best_hyperparamters`를 이용해서 가장 좋은 하이퍼파라미터 추출\n",
    "- 추출한 하이퍼파라미터를 build_model()에 넣어서 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e8f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best hyperparameters\n",
    "best_hps = my_keras_tuner.get_best_hyperparameters(num_trials=10)[0]\n",
    "\n",
    "# Make the best model with the hyperparameters\n",
    "model = build_model(best_hps)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e2fdf1",
   "metadata": {},
   "source": [
    "## Train & Evaluate model\n",
    "- 위에서 만든 모델로 학습후 모델평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f233df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fca274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f200734",
   "metadata": {},
   "source": [
    "## Save model\n",
    "- HDF5(.h5) 저장방식은 TensorFlow나 Keras에서 선호하지않는 방식\n",
    "- TensorFlow 공식 지원하는 모델저장방식은 'SavedModel'\n",
    "\n",
    "**TensorFlow SavedModel**\n",
    "- .h5파일처럼 가중치와 모델을 전부 하나의 파일로 관리X\n",
    "- **모델, 가중치를 따로 구분해서 저장 => 모델을 배포할때 유리**\n",
    "- 구성\n",
    "    - **saved_model.pb** : pb는 프로토콜 버퍼를 의미, 해당 파일은 내보낸 모델 그래프 구조를 포함\n",
    "    - **variables** : 내보낸 변수값이 있는 이진 파일, 내보낸 모델 그래프에 해당하는 체크포인트를 포함\n",
    "    - **assets** : 내보낸 모델을 불러올 때 추가적인 파일이 필요한 경우 이 폴더에 파일이 생성됨\n",
    "\n",
    "- Keras '.keras'파일 : .h5파일과 마찬가지로 가중치와 모델을 전부 하나의 파일로 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c450c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.getenv('HOME') + '/aiffel/mlops/best_model/1'\n",
    "fname = os.path.join(save_path, 'model')\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4331a5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 모델 배포\n",
    "- 배포 방식 :\n",
    "    - 클라우드 활용 배포 : TFServing\n",
    "    - 경량화된 모델생성후 휴대폰 같은 디바이스에서도 모델이 실행되도록 배포 : TFLite\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4fa446",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# TFServing \n",
    "- 텐서플로우 그래프 배포, 표준화된 엔드포인트 제공\n",
    "- 모델 및 버전관리, 정책 기반으로 모델 서비스 가능\n",
    "- 지연 시간을 최대한 짧게 만드는 고성능 처리량에 초점을 둔 방식\n",
    "\n",
    "- 방식:\n",
    "    - Docker를 활용한 배포\n",
    "    - 우분투 터미널을 활용한 배포\n",
    "        - 주의! 우분투 터미널 실습의 경우 실제 결과물이 나오려면 로컬에서 진행해야 함\n",
    "        - LMS 시스템에 들어가 있는 GPU클라우드는 Docker Image이며 쿠버네티스로 관리중\n",
    "        - **WSL2**와 **Docker 환경세팅** 필요!\n",
    "            - [WSL2 설치 + 윈도우에서 Docker 설치하기](https://axce.tistory.com/121)\n",
    "            - [파일을 우분투 디렉토리로 옮기는 방법](https://bbeomgeun.tistory.com/139)\n",
    "            - [macOS에서 Docker 설치하기](https://kplog.tistory.com/288)\n",
    "            \n",
    "## TFServing 우분투 터미널 실습\n",
    "- 우분투에 tensorflow-model-server를 설치해 배포용 텐서플로우 서버를 구축 script\n",
    "```shell\n",
    "echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
    "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
    "```\n",
    "```shell\n",
    "sudo apt update\n",
    "```\n",
    "```shell\n",
    "sudo apt install tensorflow-model-server\n",
    "```\n",
    "\n",
    "\n",
    "- 모델 배포 스크립트\n",
    "\n",
    "```shell\n",
    "tensorflow_model_server --port=8500 \\\n",
    "\t\t\t\t\t\t --rest_api_port=8501 \\\n",
    "\t\t\t\t\t\t --model_name=my_model \\\n",
    "\t\t\t\t\t\t --model_base_path=/aiffel/mlops/best_model/1/model \n",
    "```\n",
    "- `model_base_path`는 **SavedModel**이 있는 디렉토리주소\n",
    "    - 주의 : SavedModel넣을때 model 디렉토리 내부에 **숫자 '1' 폴더**를 안에 넣어야함!(?)\n",
    "    \n",
    "    \n",
    "## TFServing Docker 실습\n",
    "- 도커 설치후 \n",
    "```shell\n",
    "docker pull tensorflow/serving\n",
    "```\n",
    "\n",
    "- WSL2 shell(mac은 터미널)에 아래 명령어 실행\n",
    "```shell\n",
    "docker run -p 8500:8500 \\\n",
    "\t\t\t-p 8501:8501 \\\n",
    "\t\t\t--mount type=bind, source=/tmp/models, target=/models/my_model\n",
    "\t\t\t-e MODEL_NAME=my_model \\\n",
    "\t\t\t-e MODEL_BASE_PATH=/models/my_model \\\n",
    "\t\t\t-t tensorflow/serving\n",
    "```\n",
    "    - 첫번째 줄 : 기본포트 지정\n",
    "    - 2번째줄 : API port\n",
    "    - 3번째줄 : 모델 디렉토리 마운트\n",
    "    - 4번째줄 : 모델 이름 지정\n",
    "    - 5번째줄 : 모델의 기본경로\n",
    "    - 마지막줄 : tensorflow/serving을 사용하겠다!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2245b6",
   "metadata": {},
   "source": [
    "---\n",
    "# TFLite 경량화 모델 생성\n",
    "- TensorFlow로 만들어진 모델을 휴대폰같은 기기에서도 실행될수 있게 더 작은 모델 크기로 변환해서 배포하는데 사용하게 만드는 방법\n",
    "- TFLite의 경우 양자화라는 기법을 활용해 모델의 크기를 줄임 -> 모델의 성능이 크게 저하되지 않음\n",
    "- TensorFlow에 내장되어 있어 별도의 설치가 없이 작동하는 방식\n",
    "- `tf.lite.TFLiteConverter`메소드 활용\n",
    "\n",
    "*현재 LMS에서 tflite모델이 만들어지긴 하지만, 원인을 모르겠으나 모바일에서 tflite파일을 구동할때 중요한 '서명'이 지워진 상태로 나옴 -> Google Colab에서 만드는 것을 추천*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364cc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "load_path = os.getenv('HOME') + '/aiffel/mlops/best_model/1/model'\n",
    "best_model = tf.keras.models.load_model(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23309cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 tflite 파일 변환\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b392ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환한 tflite 파일 저장\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de7df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환이 잘 되었는지 서명부분 확인\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "\n",
    "signatures = interpreter.get_signature_list()\n",
    "print(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0acda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서명 작동하는지 확인\n",
    "classify_lite = interpreter.get_signature_runner('serving_default')\n",
    "classify_lite"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "754px",
    "left": "355px",
    "top": "0px",
    "width": "240.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
